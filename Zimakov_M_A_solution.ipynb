{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b820374a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a7938ec90606>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcatb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import probplot\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score, learning_curve\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import catboost as catb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada67643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('course_project_train.csv', encoding='utf-8')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f912d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('course_project_test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087abdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea9261f",
   "metadata": {},
   "source": [
    "Список категориальных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae0195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [col for col in train_df.columns if train_df[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5109ce8",
   "metadata": {},
   "source": [
    "Список непрерывных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196eb046",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_features = [col for col in train_df.columns if train_df[col].dtype == 'float64']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0bff2",
   "metadata": {},
   "source": [
    "Список потенциально категориальных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e2736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize = ['Tax Liens', 'Bankruptcies', 'Number of Credit Problems']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18007d29",
   "metadata": {},
   "source": [
    "Финальный список непрерывных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0df27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['Annual Income', 'Number of Open Accounts', 'Years of Credit History', 'Maximum Open Credit', 'Months since last delinquent',\n",
    "                'Current Loan Amount', 'Current Credit Balance', 'Monthly Debt', 'Credit Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e07e4d",
   "metadata": {},
   "source": [
    "Финальный список категориальных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat = ['Is_home_ownership', 'Is_stable_employment', 'Is_tax_liens', 'Is_credit_problems',\n",
    "           'Is_debt_consolidation', 'Is_longterm_credit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc294d",
   "metadata": {},
   "source": [
    "Кроссвалидация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d368c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3, random_state=43, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c753e4",
   "metadata": {},
   "source": [
    "График оценки статистической частоты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d0ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_frequency_plot(data, variables, font_scale, figsize, style):\n",
    "    sns.set(font_scale=font_scale)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.style.use(style)\n",
    "\n",
    "    for i, feature in enumerate(variables):\n",
    "        counts = data[feature].value_counts()\n",
    "\n",
    "        plt.subplot(3,2,i+1)    \n",
    "        plt.title(feature)\n",
    "        sns.barplot(counts.index, counts.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ad9e6",
   "metadata": {},
   "source": [
    "График оценки доли переменной в разрезе целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b226212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_share_plot(data, variables, font_scale, figsize, style, hue):\n",
    "    sns.set(font_scale=font_scale)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.style.use(style)\n",
    "\n",
    "    for i, feature in enumerate(variables):\n",
    "\n",
    "        plt.subplot(3,2,i+1)\n",
    "        plt.title(feature)\n",
    "        sns.countplot(x=feature, hue=hue, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd8d677",
   "metadata": {},
   "source": [
    "График доверительного интервала с расчётом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval_plot(data, variables, font_scale, figsize, style, capsize, target):\n",
    "    sns.set(font_scale=font_scale)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.style.use(style)\n",
    "    \n",
    "    for i, feature in enumerate(variables):\n",
    "       \n",
    "        plt.subplot(4,3,i+1)  \n",
    "        sns.pointplot(x=target, y=feature, data=data, capsize=capsize)\n",
    "        plt.title('95 процентный доверительный интервал для' + ' ' + feature);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6089b15",
   "metadata": {},
   "source": [
    "График оценки распределения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f3fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qq_plot(data, variables, figsize):\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    for i, feature in enumerate(variables):\n",
    "        \n",
    "        plt.subplot(4,3,i+1)\n",
    "        probplot(data[feature], dist='norm', plot=plt);\n",
    "        plt.title('Распределение' + ' ' + feature);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e334e41d",
   "metadata": {},
   "source": [
    "Расчёт критерия согласия Хи-квадрат Пирсона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09980f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_chi2(data, target, values, feature, category1, category2, aggfunc, treshold):\n",
    "    table = data.loc[data[feature].isin([category1, category2]),[values, feature, target]]\n",
    "    table[values] = table.index\n",
    "    chi2_table = table.pivot_table(values = values,\n",
    "                                   index=feature, \n",
    "                                   columns=target, \n",
    "                                   aggfunc=aggfunc)\n",
    "    chi2, p, dof, expected = chi2_contingency(chi2_table, correction=False)\n",
    "    \n",
    "    if p < treshold:\n",
    "        print(f'Разделение на категории {category1} и {category2} для {feature} статистически значимо')\n",
    "    else:\n",
    "        print(f'Разделение на категории {category1} и {category2} для {feature} статистически незначимо')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481db5f0",
   "metadata": {},
   "source": [
    "Расчёт критерия Шапиро-Уилка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a784af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_shapiro(data, variables, treshold, target):\n",
    "    for feature in data[variables]:\n",
    "        feature_with_target = data[[feature, target]]\n",
    "        feature_ = feature_with_target[feature]\n",
    "        stat, p = shapiro(feature_)\n",
    "        \n",
    "        if p < treshold:\n",
    "            print(f'Гипотеза о нормальном распределении для {feature} отвергается')\n",
    "        else:\n",
    "            print(f'Гипотеза о нормальном распределении для {feature} принимается')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb1aca6",
   "metadata": {},
   "source": [
    "Проверка гипотез о зависимости признаков с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependency_hypo(data, variables, treshold, target):\n",
    "    \n",
    "    for feature in data[variables]:\n",
    "        feature_with_target = data[[feature,target]]\n",
    "        feature_ = feature_with_target[feature]\n",
    "        stat, p = shapiro(feature_)\n",
    "    \n",
    "        feature_0 = feature_[feature_with_target[target] == 0]\n",
    "        feature_1 = feature_[feature_with_target[target] == 1]\n",
    "        \n",
    "        if p < treshold:\n",
    "            stat, p_= mannwhitneyu(feature_0, feature_1)\n",
    "\n",
    "            if p_< treshold:\n",
    "                print(f'Гипотеза о равенстве мат.ожиданий для {feature} отвергается')\n",
    "            else:\n",
    "                print(f'Гипотеза о равенстве мат.ожиданий для {feature} принимается')\n",
    "                  \n",
    "        else:\n",
    "            stat, p_= ttest_ind(feature_0, feature_1)\n",
    "\n",
    "            if p_< treshold:\n",
    "                print(f'Гипотеза о равенстве мат.ожиданий для {feature} отвергается')\n",
    "            else:\n",
    "                print(f'Гипотеза о равенстве мат.ожиданий для {feature} принимается')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16058e53",
   "metadata": {},
   "source": [
    "График для оценки корреляций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_plot(data, method):\n",
    "    plt.figure(figsize = (14,14))\n",
    "\n",
    "    sns.set(font_scale=1)\n",
    "    sns.heatmap(data.corr(method).round(2), annot=True, linewidths=.5, cmap='coolwarm')\n",
    "    plt.title('Матрица корреляций');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffbea2",
   "metadata": {},
   "source": [
    "Отчёт по оценке модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
    "    print('TRAIN\\n\\n' + classification_report(y_train_true, y_train_pred))\n",
    "    print('TEST\\n\\n' + classification_report(y_test_true, y_test_pred))\n",
    "    print('CONFUSION MATRIX\\n')\n",
    "    print(pd.crosstab(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562da296",
   "metadata": {},
   "source": [
    "Отчёт по коэффициентам логита."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coef_report(data, model):\n",
    "    count = 0\n",
    "    for column in data.columns:\n",
    "        print((np.round(model.coef_[0][count], decimals=3)), column)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0153ff3",
   "metadata": {},
   "source": [
    "Балансировка классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df_by_target(df, target_name):\n",
    "\n",
    "    target_counts = df[target_name].value_counts()\n",
    "\n",
    "    major_class_name = target_counts.argmax()\n",
    "    minor_class_name = target_counts.argmin()\n",
    "\n",
    "    disbalance_coeff = int(target_counts[major_class_name] / target_counts[minor_class_name]) - 1\n",
    "\n",
    "    for i in range(disbalance_coeff):\n",
    "        sample = df[df[target_name] == minor_class_name].sample(target_counts[minor_class_name])\n",
    "        df = df.append(sample, ignore_index=True)\n",
    "\n",
    "    return df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b40e4",
   "metadata": {},
   "source": [
    "Функции для создания новых признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84573a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#квадраты непрерывных признаков\n",
    "def parabolize(data, power, features):\n",
    "    for i in features:\n",
    "        name = i + 'power'\n",
    "        data[name] = np.power(data[i], power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262224c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#логарифмы непрерывных признаков\n",
    "def get_log(data, features):\n",
    "    for i in features:\n",
    "        name = i + 'log'\n",
    "        data[name] = np.log(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f812260",
   "metadata": {},
   "source": [
    "График кривых валидации и обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac03f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_learning_curve_plot(estimator, X, y, cv=3, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, \n",
    "                                                            cv=cv, \n",
    "                                                            scoring='f1',\n",
    "                                                            train_sizes=train_sizes, \n",
    "                                                            n_jobs=n_jobs)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.title(f\"Learning curves ({type(estimator).__name__})\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")     \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a4e506",
   "metadata": {},
   "source": [
    "График для оценки калибровки классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c5f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_proba_calibration_plots(y_predicted_probs, y_true_labels):\n",
    "    preds_with_true_labels = np.array(list(zip(y_predicted_probs, y_true_labels)))\n",
    "\n",
    "    thresholds = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for threshold in np.linspace(0.1, 0.9, 9):\n",
    "        thresholds.append(threshold)\n",
    "        precisions.append(precision_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n",
    "        recalls.append(recall_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n",
    "        f1_scores.append(f1_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n",
    "\n",
    "    scores_table = pd.DataFrame({'f1':f1_scores,\n",
    "                                 'precision':precisions,\n",
    "                                 'recall':recalls,\n",
    "                                 'probability':thresholds}).sort_values('f1', ascending=False).round(3)\n",
    "      \n",
    "    figure = plt.figure(figsize = (15, 5))\n",
    "\n",
    "    plt1 = figure.add_subplot(121)\n",
    "    plt1.axhline(0.5, color=\"red\")\n",
    "    plt1.plot(thresholds, precisions, label='Precision', linewidth=4)\n",
    "    plt1.plot(thresholds, recalls, label='Recall', linewidth=4)\n",
    "    plt1.plot(thresholds, f1_scores, label='F1', linewidth=4)\n",
    "    plt1.set_ylabel('Scores')\n",
    "    plt1.set_xlabel('Probability threshold')\n",
    "    plt1.set_title('Probabilities threshold calibration')\n",
    "    plt1.legend(bbox_to_anchor=(0.25, 0.25))   \n",
    "    plt1.table(cellText = scores_table.values,\n",
    "               colLabels = scores_table.columns, \n",
    "               colLoc = 'center', cellLoc = 'center', loc = 'bottom', bbox = [0, -1.3, 1, 1])\n",
    "\n",
    "    plt2 = figure.add_subplot(122)\n",
    "    plt2.hist(preds_with_true_labels[preds_with_true_labels[:, 1] == 0][:, 0], \n",
    "              label='Another class', color='royalblue', alpha=0.5)\n",
    "    plt2.hist(preds_with_true_labels[preds_with_true_labels[:, 1] == 1][:, 0], \n",
    "              label='Main class', color='darkcyan', alpha=0.8)\n",
    "    plt2.set_ylabel('Number of examples')\n",
    "    plt2.set_xlabel('Probabilities')\n",
    "    plt2.set_title('Probability histogram')\n",
    "    plt2.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16268adb",
   "metadata": {},
   "source": [
    "График feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importances(feature_names, feature_importances, get_top=None):\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "    feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "       \n",
    "    plt.figure(figsize = (20, len(feature_importances) * 0.355))\n",
    "    \n",
    "    sns.barplot(feature_importances['importance'], feature_importances['feature'])\n",
    "    \n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Importance of features')\n",
    "    plt.show()\n",
    "\n",
    "    if get_top is not None:\n",
    "        return feature_importances['feature'][:get_top].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745da818",
   "metadata": {},
   "source": [
    "# Анализ категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_frequency_plot(df, cat_features, 0.9, (18,18), 'seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f893e2",
   "metadata": {},
   "source": [
    "Кроме переменной \"срок кредита\", категорий довольно много. Для всех переменных характерен дисбаланс категорий, т.е. одни категории встречаются очень часто, а другие - довольно редко. Проведу оценку этих признаков в разрезе целевой переменной, чтобы понять оптимальное количество групп, на которые стоит разбивать эти признаки. Для этого буду использовать критерий хи-квадрат Пирсона на уровне значимости 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f1f4d",
   "metadata": {},
   "source": [
    "Метод позволяет оценить статистическую значимость различий двух или нескольких относительных показателей (частот, долей)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558c9c4",
   "metadata": {},
   "source": [
    "$x^n = (x_1, .. , x_n), \\: x^n \\in X$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fbb326",
   "metadata": {},
   "source": [
    "$H_0:$ Эмпирические (наблюдаемые) и теоретические (ожидаемые) частоты согласованы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e46c6b",
   "metadata": {},
   "source": [
    "$H_1: \\: H_0 \\:$ неверна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a6e48",
   "metadata": {},
   "source": [
    "$$\\chi^2 = \\sum_{i=1}^K \\frac{(O_i - E_i)^2}{E_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fcc637",
   "metadata": {},
   "source": [
    "$O$ (Observed) - наблюдаемые частоты \\\n",
    "$E$ (Expected) - ожидаемые частоты \\\n",
    "$K$ - количество оцениваемых частот"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7681d0",
   "metadata": {},
   "source": [
    "$\\chi^2 \\sim \\chi^2(\\mathit{df})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e21f0fd",
   "metadata": {},
   "source": [
    "Сопоставляемые группы должны быть независимыми, то есть критерий хи-квадрат не должен применяться при сравнении наблюдений \"до-после\" или связанных пар. Аналог для зависимых выборок - тест Мак-Немара или Q-критерий Кохрена для сравнения трех и более групп."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9f3aa",
   "metadata": {},
   "source": [
    "Если в ячейке меньше 10 наблюдений, применяется поправка Йетса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13faf2a",
   "metadata": {},
   "source": [
    "Если меньше 5, то вместо хи-квадрат используется точный тест Фишера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f125674",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_share_plot(train_df, cat_features, 0.9, (18,18), 'seaborn-white', 'Credit Default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c786933",
   "metadata": {},
   "source": [
    "Визуальная оценка графиков позволяет сделать следующие гипотезы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc612d6",
   "metadata": {},
   "source": [
    "Для переменной Home Ownership доля целевого признака во всех категориях примерно одинакова. Такая же картина наблюдается для переменной Years in current job, а также для переменной Purpose. Для переменной Term доля целевой переменной в категориях не одинакова. Теперь проверю эти гипотезы, используя расчётный тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_chi2(data=train_df, target='Credit Default', values='id',\n",
    "          feature='Home Ownership', category1='Own Home', \n",
    "          category2='Rent', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_chi2(data=train_df, target='Credit Default', values='id',\n",
    "          feature='Home Ownership', category1='Rent', \n",
    "          category2='Home Mortrage', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c28438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_chi2(data=train_df, target='Credit Default', values='id',\n",
    "          feature='Years in current job', category1='10+ years', \n",
    "          category2='1 year', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_chi2(data=train_df, target='Credit Default', values='id',\n",
    "          feature='Purpose', category1='debt consolidation', \n",
    "          category2='home improvements', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_chi2(data=train_df, target='Credit Default', values='id',\n",
    "          feature='Term', category1='Short Term', \n",
    "          category2='Long Term', aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195f6f2",
   "metadata": {},
   "source": [
    "Расчётные значения подтвердили гипотезы. На уровне значимости 0.05 у нас нет оснований отвергать нулевую гипотезу только для переменной Short Term. Только для срока кредита разбиение на категории статистически значимо."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575f2aa",
   "metadata": {},
   "source": [
    "В остальных переменных оставлю только одну категорию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264f5fe",
   "metadata": {},
   "source": [
    " ##### Is_home_ownership - наличие права собственности на жилую площадь \n",
    " ##### Is_stable_employment - заёмщик на текущем месте работы более 10 лет \n",
    " ##### Is_debt_consolidation - кредит берётся на покрытие другого кредита \n",
    " ##### Is_longterm_credit - кредит береётся на длительный срок "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns={'Home Ownership': 'Is_home_ownership',\n",
    "               'Years in current job': 'Is_stable_employment',\n",
    "               'Purpose': 'Is_debt_consolidation'}, \n",
    "               inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddf57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.rename(columns={'Home Ownership': 'Is_home_ownership',\n",
    "               'Years in current job': 'Is_stable_employment',\n",
    "               'Purpose': 'Is_debt_consolidation'}, \n",
    "               inplace=True)test_df.rename(columns={'Home Ownership': 'Is_home_ownership',\n",
    "               'Years in current job': 'Is_stable_employment',\n",
    "               'Purpose': 'Is_debt_consolidation'}, \n",
    "               inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5fe5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Is_home_ownership'] = train_df['Is_home_ownership'].replace({'Home Mortgage': 1, 'Own Home': 1, \n",
    "                                                                     'Have Mortgage': 1, 'Rent': 0})\n",
    "test_df['Is_home_ownership'] = test_df['Is_home_ownership'].replace({'Home Mortgage': 1, 'Own Home': 1, \n",
    "                                                                     'Have Mortgage': 1, 'Rent': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db476170",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Is_stable_employment'] = train_df['Is_stable_employment'].replace({'2 years': 1, '3 years': 1, '< 1 year': 1,\n",
    "                                                                            '5 years': 1, '1 year': 1, '4 years': 1,\n",
    "                                                                            '6 years': 1, '7 years': 1, '8 years': 1,\n",
    "                                                                            '9 years': 1, '10+ years': 0})\n",
    "test_df['Is_stable_employment'] = test_df['Is_stable_employment'].replace({'2 years': 1, '3 years': 1, '< 1 year': 1,\n",
    "                                                                            '5 years': 1, '1 year': 1, '4 years': 1,\n",
    "                                                                            '6 years': 1, '7 years': 1, '8 years': 1,\n",
    "                                                                            '9 years': 1, '10+ years': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70249a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Is_debt_consolidation'] = train_df['Is_debt_consolidation'].replace({'other': 1, 'home improvements': 1, \n",
    "                                                                              'business loan': 1, 'buy a car': 1,\n",
    "                                                                              'medical bills': 1, 'major purchase': 1,\n",
    "                                                                              'take a trip': 1, 'buy house': 1,\n",
    "                                                                              'small business': 1, 'wedding': 1,\n",
    "                                                                              'moving': 1, 'educational expenses': 1,\n",
    "                                                                              'vacation': 1, 'renewable energy': 1,\n",
    "                                                                              'debt consolidation': 0})\n",
    "test_df['Is_debt_consolidation'] = test_df['Is_debt_consolidation'].replace({'other': 1, 'home improvements': 1, \n",
    "                                                                              'business loan': 1, 'buy a car': 1,\n",
    "                                                                              'medical bills': 1, 'major purchase': 1,\n",
    "                                                                              'take a trip': 1, 'buy house': 1,\n",
    "                                                                              'small business': 1, 'wedding': 1,\n",
    "                                                                              'moving': 1, 'educational expenses': 1,\n",
    "                                                                              'vacation': 1, 'renewable energy': 1,\n",
    "                                                                              'debt consolidation': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3af54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns={'Term': 'Is_longterm_credit'}, \n",
    "               inplace=True)\n",
    "test_df.rename(columns={'Term': 'Is_longterm_credit'}, \n",
    "               inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Is_longterm_credit'] = train_df['Is_longterm_credit'].replace({'Short Term': 1, 'Long Term': 0})\n",
    "test_df['Is_longterm_credit'] = test_df['Is_longterm_credit'].replace({'Short Term': 1, 'Long Term': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Is_home_ownership'] = train_df['Is_home_ownership'].astype('str')\n",
    "train_df['Is_stable_employment'] = train_df['Is_stable_employment'].astype('str')\n",
    "train_df['Is_debt_consolidation'] = train_df['Is_debt_consolidation'].astype('str')\n",
    "train_df['Is_longterm_credit'] = train_df['Is_longterm_credit'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464eca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Is_home_ownership'] = test_df['Is_home_ownership'].astype('str')\n",
    "test_df['Is_stable_employment'] = test_df['Is_stable_employment'].astype('str')\n",
    "test_df['Is_debt_consolidation'] = test_df['Is_debt_consolidation'].astype('str')\n",
    "test_df['Is_longterm_credit'] = test_df['Is_longterm_credit'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1efa53",
   "metadata": {},
   "source": [
    "# Анализ непрерывных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e80bb20",
   "metadata": {},
   "source": [
    "Построим доверительные интервалы для средних значений каждой из двух групп и сравним их."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18904e9e",
   "metadata": {},
   "source": [
    "Доверительный интервал - это вид интервальной оценки, которая задаёт числовые границы, в которых с определённой вероятностью находится истинное значение оцениваемого параметра."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a4218f",
   "metadata": {},
   "source": [
    "### Порядок расчета доверительного интервала (для мат. ожидания)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e470e6",
   "metadata": {},
   "source": [
    "1.Задать уровень достоверности (confidence level), $\\alpha = 95\\% = 0.95$ \\\n",
    "2.Найти по таблице Z-оценок или рассчитать коэффициент достоверности (confidence coefficient) - $ Z_{\\alpha/2}$, для $\\alpha = 0.95, Z_{\\alpha/2} = 1.96$ \\\n",
    "3.Рассчитать доверительный интервал (confidence interval):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384bc0a",
   "metadata": {},
   "source": [
    "$$ CI = \\overline{x} \\pm Z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caedfca",
   "metadata": {},
   "source": [
    "где $ \\bar{x}$ - выборочное среднее, $ \\sigma$ - стандартное отклонение, $ n$ - размер выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29587836",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_plot(data=train_df, variables=nom_features, \n",
    "                         font_scale=0.9, figsize=(18,18), \n",
    "                         style='seaborn-white', capsize=.1,\n",
    "                         target='Credit Default');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406a956",
   "metadata": {},
   "source": [
    "На 95 процентном доврительном интервале средние значения для переменных Months since last delinquent и Bankruptcies практически одинаково. Для остальных непрерывных признаков выборочные средние различаются. Это может говорить о том, что эти две переменные не оказывают функциональной зависимости на целевую переменную. Проверим эту гипотезу при помощи анализа распределений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e9266",
   "metadata": {},
   "source": [
    "Оценим распределение визуально при помощи qq-plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot(train_df, nom_features, figsize=(18,18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa69b7f",
   "metadata": {},
   "source": [
    "Из графиков функций распределения видно, что для некоторых переменных функции распределения выглядят ступенчатыми. С большой долей вероятности эти переменные являются категриальными:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef258c",
   "metadata": {},
   "source": [
    "1.Tax Liens \\\n",
    "2.Bancruptcies \\\n",
    "3.Number of credit problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18931460",
   "metadata": {},
   "source": [
    "Также отметим довольно странные выбросы в переменной Credit Score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa6a56",
   "metadata": {},
   "source": [
    "Проверю гипотезу о нормальном распределении при помощи критерия Шапиро-Уилка."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f08e2",
   "metadata": {},
   "source": [
    "Данный критерий проверяет гипотезу о том, что некоторая случайная величина имеет нормальное распределение (распределение Гаусса). Необходимость проверять случайную величину на \"нормальность\", обусловлена тем, что многие статистические критерии и аналитические методы из мат. статистики ориентированы на выборки из нормально распределённых случайных величин и перед их использованием необходимо убедиться в том, что закон распределения приближен к нормальному.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f98d1",
   "metadata": {},
   "source": [
    "$x^n = (x_1, .. , x_n), \\: x^n \\in X$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c8272",
   "metadata": {},
   "source": [
    "$H_0: \\: X \\sim N(\\mu, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85446543",
   "metadata": {},
   "source": [
    "$$W = \\frac{(\\sum_{i=1}^n a_i x_i)^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_shapiro(data=train_df, variables=nom_features, \n",
    "             treshold=0.05, target='Credit Default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d493a58",
   "metadata": {},
   "source": [
    "Гипотеза о нормальном распределении для Annual Income принимается \\\n",
    "Гипотеза о нормальном распределении для Tax Liens отвергается \\\n",
    "Гипотеза о нормальном распределении для Number of Open Accounts отвергается \\\n",
    "Гипотеза о нормальном распределении для Years of Credit History отвергается \\\n",
    "Гипотеза о нормальном распределении для Maximum Open Credit отвергается \\\n",
    "Гипотеза о нормальном распределении для Number of Credit Problems отвергается \\\n",
    "Гипотеза о нормальном распределении для Months since last delinquent принимается \\\n",
    "Гипотеза о нормальном распределении для Bankruptcies принимается \\\n",
    "Гипотеза о нормальном распределении для Current Loan Amount отвергается \\\n",
    "Гипотеза о нормальном распределении для Current Credit Balance отвергается \\\n",
    "Гипотеза о нормальном распределении для Monthly Debt отвергается \\\n",
    "Гипотеза о нормальном распределении для Credit Score принимается"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7543ad4",
   "metadata": {},
   "source": [
    "Проведу оценку возможной функциональной зависимости при помощи t-критерия Стьюдента для признаков с нормальным распредлением и критерий Манна-Уитни для признаков с распределением, отличного от нормального."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db7f5d",
   "metadata": {},
   "source": [
    "Критерий Стьюдента* — общее название для статистических тестов, в которых статистика критерия имеет распределение Стьюдента.\n",
    "Наиболее часто данные критерии применяются для проверки равенства средних значений (мат. ожиданий) в двух выборках."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74ee81",
   "metadata": {},
   "source": [
    "$ x_1^{n_1} = (x_{11}, .. , x_{1{n_1}}), \\: x_1^{n_1} \\in X_1, \\: X_1 \\sim \\mathrm{N}(\\mu_1, \\sigma_1^2), \\sigma_1 неизвестна$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04023e42",
   "metadata": {},
   "source": [
    "$ x_2^{n_2} = (x_{21}, .. , x_{2{n_2}}), \\: x_2^{n_2} \\in X_2, \\: X_2 \\sim \\mathrm{N}(\\mu_2, \\sigma_2^2), \\sigma_2 неизвестна$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8c328e",
   "metadata": {},
   "source": [
    "$H_0: \\: \\mu_1 = \\mu_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7ff73",
   "metadata": {},
   "source": [
    "$H_1: \\: \\mu_1 \\ne \\mu_2\\text{ либо }\\mu_1 &lt; \\mu_2\\text{ либо }\\mu_1 &gt; \\mu_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd1365c",
   "metadata": {},
   "source": [
    "$$T(x_1^{n_1}, x_2^{n_2}) = \\frac{\\overline{x_1} \\: - \\: \\overline{x_2}}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eedf23",
   "metadata": {},
   "source": [
    "$T(x_1^{n_1}, x_2^{n_2}) \\sim \\mathrm{t }(\\mathit{df}=n_1+n_2-2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b489379",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_hypo(data=train_df, variables=nom_features, treshold=0.05, target='Credit Default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f533f",
   "metadata": {},
   "source": [
    "Гипотеза о равенстве мат.ожиданий для Annual Income принимается \\\n",
    "Гипотеза о равенстве мат.ожиданий для Tax Liens отвергается \\\n",
    "Гипотеза о равенстве мат.ожиданий для Number of Open Accounts отвергается \\\n",
    "Гипотеза о равенстве мат.ожиданий для Years of Credit History отвергается \\\n",
    "Гипотеза о равенстве мат.ожиданий для Maximum Open Credit отвергается \\\n",
    "Гипотеза о равенстве мат.ожиданий для Number of Credit Problems принимается \\\n",
    "Гипотеза о равенстве мат.ожиданий для Months since last delinquent принимается \\\n",
    "Гипотеза о равенстве мат.ожиданий для Bankruptcies принимается \\\n",
    "Гипотеза о равенстве мат.ожиданий для Current Loan Amount отвергается \\\n",
    "Гипотеза о равенстве мат.ожиданий для Current Credit Balance принимается \\\n",
    "Гипотеза о равенстве мат.ожиданий для Monthly Debt отвергается \\\n",
    "Гипотеза о равенстве мат.ожиданий для Credit Score принимается"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4276f5f",
   "metadata": {},
   "source": [
    "Для переменных Months since last delinquent и Bankruptcies результаты по доверительным интервалам совпадают с расчётными статистическими критериями. Однако, расчётные критерии показали, что для переменных Annual Income и Credit Score нет функциональной зависимости с целевой переменной. Это возможно из-за довольно высокой жёсткости критерия Шапиро-Уилка. Если применить менее жёсткий критерий Колмогорова-Смирнова, результаты могут отличаться."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb4f61",
   "metadata": {},
   "source": [
    "Воспользуемся снова критерием хи-квадрат для потенциально новых категориальных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_share_plot(train_df, categorize, 0.9, (18,18), 'seaborn-white', 'Credit Default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abe4770",
   "metadata": {},
   "source": [
    "Для переменной Tax Liens крайне мало значений больше нуля. Аналогично для двух других переменных. Для Bancruptcies и Number of Credit Problems очень мало значений больше 1. Проверю расчётно гипотезы о значимости доли разбиения переменных по категориям для Bancruptcies и Number of Credit Problems. Визуально можно отметить, что разделение более чем на одну группу статистически незначимо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a07afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_chi2(data=train_df, target='Credit Default', values='id',\n",
    "          feature='Number of Credit Problems', category1='0.0', \n",
    "          category2='1.0', aggfunc='count', treshold=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71648f",
   "metadata": {},
   "source": [
    "Разделение на категории 0.0 и 1.0 для Number of Credit Problems статистически незначимо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9392b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_chi2(data=train_df, target='Credit Default', values='id',\n",
    "          feature='Bankruptcies', category1='0.0', \n",
    "          category2='1.0', aggfunc='count', treshold=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f976819",
   "metadata": {},
   "source": [
    "Разделение на категории 0.0 и 1.0 для Bankruptcies статистически незначимо"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d36bcb6",
   "metadata": {},
   "source": [
    "Так и есть. На уровне значимости 0.05 есть основания отвергать нулевую гипотезу, поэтому разобью эти переменные на одну категорию. Однако, скорее всего, эти переменные окажутся не сильно значимыми, поскольку есть довольно сильный перекос в сторону одного конкретного значения. Да и доверительные интервалы намекают на это."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a380fc1",
   "metadata": {},
   "source": [
    " ##### Is_tax_liens - есть налоговый залог.\n",
    " ##### Is_bancruptcies - факт наличия банкроства.\n",
    " ##### Is_credit_problems - факт наличия проблем с выплатой кредита."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns={'Tax Liens': 'Is_tax_liens',\n",
    "               'Bankruptcies': 'Is_bancruptcies',\n",
    "               'Number of Credit Problems': 'Is_credit_problems'}, \n",
    "               inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff3d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.rename(columns={'Tax Liens': 'Is_tax_liens',\n",
    "               'Bankruptcies': 'Is_bancruptcies',\n",
    "               'Number of Credit Problems': 'Is_credit_problems'}, \n",
    "               inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b7da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Is_tax_liens'] = train_df['Is_tax_liens'].replace({0.0: 1, 1.0: 0, 2.0: 0,\n",
    "                                                            3.0: 0, 4.0: 0, 5.0: 0,\n",
    "                                                            6.0: 0, 7.0: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000528f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Is_tax_liens'] = test_df['Is_tax_liens'].replace({0.0: 1, 1.0: 0, 2.0: 0,\n",
    "                                                            3.0: 0, 4.0: 0, 5.0: 0,\n",
    "                                                            6.0: 0, 7.0: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a2cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Is_bancruptcies'] = train_df['Is_bancruptcies'].replace({0.0: 1, 1.0: 0, 2.0: 0,\n",
    "                                                            3.0: 0, 4.0: 0, 5.0: 0,\n",
    "                                                            6.0: 0})\n",
    "test_df['Is_bancruptcies'] = test_df['Is_bancruptcies'].replace({0.0: 1, 1.0: 0, 2.0: 0,\n",
    "                                                            3.0: 0, 4.0: 0, 5.0: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c3f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Is_credit_problems'] = train_df['Is_credit_problems'].replace({0.0: 1, 1.0: 0, 2.0: 0,\n",
    "                                                            3.0: 0, 4.0: 0, 5.0: 0,\n",
    "                                                            6.0: 0, 7.0: 0})\n",
    "test_df['Is_credit_problems'] = test_df['Is_credit_problems'].replace({0.0: 1, 1.0: 0, 2.0: 0,\n",
    "                                                            3.0: 0, 4.0: 0, 5.0: 0,\n",
    "                                                            6.0: 0, 7.0: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa061718",
   "metadata": {},
   "source": [
    "# Анализ признакового пространства"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb3018",
   "metadata": {},
   "source": [
    "Проверим наличие мультиколлинеарности при помощи корреляции Пирсона для непрерывных признаков и корреляции Спирмэна для категориальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_plot(data=train_df, method='pearson');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73589b",
   "metadata": {},
   "source": [
    "Признаки практически не имеют линейной зависимости друг с другом, наблюдается частичная мультиколлинеарность. Имеющиеся признаки довольно уникальны."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de1e8c9",
   "metadata": {},
   "source": [
    "# Заполнение пропущенных значений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b9c3c",
   "metadata": {},
   "source": [
    "Пропуски в непрерывных признаках заполню медианой, чтобы избежать выбросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Annual Income'].isna(), 'Annual Income'] = train_df['Annual Income'].median()\n",
    "train_df.loc[train_df['Months since last delinquent'].isna(), 'Months since last delinquent'] = train_df['Months since last delinquent'].median()\n",
    "train_df.loc[train_df['Credit Score'].isna(), 'Credit Score'] = train_df['Credit Score'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca478651",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['Annual Income'].isna(), 'Annual Income'] = train_df['Annual Income'].median()\n",
    "test_df.loc[test_df['Months since last delinquent'].isna(), 'Months since last delinquent'] = train_df['Months since last delinquent'].median()\n",
    "test_df.loc[test_df['Credit Score'].isna(), 'Credit Score'] = train_df['Credit Score'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01abe6ec",
   "metadata": {},
   "source": [
    "Пропуски в категориальных переменных заполню модой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Is_stable_employment'].isna(), 'Is_stable_employment'] = train_df['Is_stable_employment'].mode()[0]\n",
    "train_df.loc[train_df['Is_bancruptcies'].isna(), 'Is_bancruptcies'] = train_df['Is_bancruptcies'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['Is_bancruptcies'].isna(), 'Is_bancruptcies'] = test_df['Is_bancruptcies'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14bbf6b",
   "metadata": {},
   "source": [
    "Сохраню предобработанный датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_processed.csv', encoding='utf-8', index=False)\n",
    "test_df.to_csv('test_processed.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f4c7a",
   "metadata": {},
   "source": [
    "# Анализ целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Credit Default', data = train_df, palette=\"Set3\")\n",
    "plt.title('Распределение целевой переменной Credit Default', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Credit Default'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f55db96",
   "metadata": {},
   "source": [
    "# Ключевые гипотезы и выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f01b81",
   "metadata": {},
   "source": [
    "1. Ключевые гипотезы и выводы \\\n",
    "2. С вероятностью 95% переменные Months since last delinquent и Bankruptcies не являются значимыми для построения модели. \\\n",
    "3. Изначально отмеченные как непрерывные, переменные Tax Liens, Bancruptcies и Number of credit problems оказались категориальными, поскольку обладают ступенчатым распределением. Каждая из этих переменных приведена к категориальным с одной группой путём one hot encoding. Tax Liens и Number of credit problems скорее всего, окажутся слабо значимыми для построения модели. \\\n",
    "4. Парный коэффициент корреляции Пирсона показал незначительную частичную мультиколлинеарность и очень слабую линейную связь между признаками и целевой переменной. Возможно, есть нелинейные взимосвязи. \\\n",
    "5. Балансировка классов может помочь в улучшении качества модели. \\\n",
    "6. Имеет смысл в качестве бэйзлайна построить логистическую регрессию и дерево решений для финальной оценки взаимосвязей и проверки результатов стастических гипотез из раздела 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a964aea",
   "metadata": {},
   "source": [
    "# Получение бэйзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_processed.csv', encoding='utf-8')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d6a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Is_stable_employment'].isna(), 'Is_stable_employment'] = train_df['Is_stable_employment'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dbe289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = train_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebc4f90",
   "metadata": {},
   "source": [
    "Отмасштабируем непрерывные признаки, поскольку используем линейную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252831b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "df_norm[num_features] = scaler.fit_transform(df_norm[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac2e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f992577",
   "metadata": {},
   "source": [
    "Организуем отложенную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_norm['Credit Default']\n",
    "X = df_norm.drop('Credit Default', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.25, \n",
    "                                                    random_state=43) #lets be special"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5d19c",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1',\n",
    "                       tol=1e-8, #критерий останова\n",
    "                        C=1e-2, #немножко регуляризации\n",
    "                       class_weight='balanced', \n",
    "                       random_state=43,\n",
    "                       max_iter=400, #количество итераций\n",
    "                       n_jobs=-1,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c4c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "get_classification_report(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f116ba9",
   "metadata": {},
   "source": [
    "Посмотрим на коэффициенты при переменных, значимые и незначимые признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda97ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coef_report(X, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1072c",
   "metadata": {},
   "source": [
    "Наилучшую модель логистической регрессии удалось построить, применив l1 регуляризацию. Модель подтвердила статистические гипотезы из раздела 3. Также можно заметить, что не занулились коэффициенты с максимальным различием среднего значения в разрезе целевой переменной. В целом, модель получилась довольно консервативной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0103f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logit.pickle', 'wb') as f:\n",
    "    pickle.dump(lr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127a625",
   "metadata": {},
   "source": [
    "# Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Is_home_ownership',\n",
    " 'Annual Income',\n",
    " 'Is_stable_employment',\n",
    " 'Is_tax_liens',\n",
    " 'Number of Open Accounts',\n",
    " 'Years of Credit History',\n",
    " 'Maximum Open Credit',\n",
    " 'Is_credit_problems',\n",
    " #'Months since last delinquent',\n",
    " #'Is_bancruptcies',\n",
    " 'Is_debt_consolidation',\n",
    " 'Is_longterm_credit',\n",
    " 'Current Loan Amount',\n",
    " 'Current Credit Balance',\n",
    " 'Monthly Debt',\n",
    " 'Credit Score',\n",
    " 'Credit Default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bba1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['Credit Default']\n",
    "X = train_df[features].drop('Credit Default', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_features='sqrt',random_state=43, \n",
    "                            class_weight='balanced', min_impurity_split=1e-3,\n",
    "                            criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {'max_depth': np.arange(6, 15), #максимальная глубина дерева\n",
    "             'min_samples_leaf': np.arange(1, 5),\n",
    "            'max_leaf_nodes': [100, 500, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gs = GridSearchCV(dt, dt_params, scoring='f1', n_jobs=-1, cv=cv)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dbbdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9df436",
   "metadata": {},
   "source": [
    "Наилучшее значение метрики для дерева получилось без переменных Months since last delinquent и Is_bancruptcies, что подтвердило результат проверки статистических гипотез. Значение целевой метрики оказалось чуть ниже, чем в логистической регрессии, однако эта модель не такая консервативная. Между остальными признаками(друг с другом) и с целевой переменной подтвердилось наличие нелинейной взаимосвязи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24ae49",
   "metadata": {},
   "source": [
    "# Ансамблевые алгоритмы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95973af",
   "metadata": {},
   "source": [
    "Теперь прогоним на дефолтных гиперпараметрах следующие алгоритмы:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c177e",
   "metadata": {},
   "source": [
    "    1. Случайный лес \n",
    "    2. Многослойный перцептрон \n",
    "    3. Различные реализации градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['Credit Default']\n",
    "X = train_df[features].drop('Credit Default', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "random_state = 18\n",
    "classifiers = []\n",
    "\n",
    "classifiers.append(RandomForestClassifier(random_state=random_state))\n",
    "classifiers.append(GradientBoostingClassifier(random_state=random_state))\n",
    "classifiers.append(MLPClassifier(random_state=random_state))\n",
    "classifiers.append(AdaBoostClassifier(random_state=random_state))\n",
    "classifiers.append(xgb.XGBClassifier(random_state=random_state))\n",
    "classifiers.append(lgbm.LGBMClassifier(random_state=random_state))\n",
    "classifiers.append(catb.CatBoostClassifier(random_state=random_state))\n",
    "\n",
    "cv_results = []\n",
    "for classifier in classifiers :\n",
    "    cv_results.append(cross_val_score(classifier, X, y = y, scoring = 'f1', cv = cv, n_jobs=-1))\n",
    "\n",
    "cv_means = []\n",
    "cv_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "\n",
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\n",
    "\"RandomForest\", \"GradientBoosting\",\"MultipleLayerPerceptron\", \"AdaBoost\", \"XGB\", \"LGBM\", \"CatBoost\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5508b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\n",
    "g.set_xlabel(\"Mean F1\")\n",
    "g = g.set_title(\"Cross validation scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8ddbe",
   "metadata": {},
   "source": [
    "Все алгоритмы, кроме XGBoost показали приблизительно одинаковый результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e534df",
   "metadata": {},
   "source": [
    "# Создание новых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726fc895",
   "metadata": {},
   "source": [
    "Поскольку мы подтвердили наличие нелинейной функциональной зависимости между признаками и целевой переменной, создам новые признаки:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4008ea4",
   "metadata": {},
   "source": [
    "- Квадраты непрерывных переменных \n",
    "- Логарифмы непрерывных переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ab00e",
   "metadata": {},
   "source": [
    "Квадраты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "parabolize(train_df, 2, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958496f",
   "metadata": {},
   "source": [
    "Логарифмы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_log(train_df, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b721639",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_features.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b0223e",
   "metadata": {},
   "source": [
    "# Настройка гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cedc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_features.csv', encoding='utf-8')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92d29e",
   "metadata": {},
   "source": [
    "Результат немногим лучше логистической регресии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac236114",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfc779e",
   "metadata": {},
   "source": [
    "В LightGBM применяется Gradient-based One-Side Sampling(GOSS). Ключевая идея этой техники заключается в том, что на каждой эпохе обучения выбирается наиболее значимый - с максимально возможным градиентом, т.е. таким значением градиента, который наиболее сильно влияет на минимизацию функции потерь. На каждой эпохе обучения из общего количества объектов выбираются только те объекты, который имеют максимальный градиент плюс с остального количества некоторый рандомный процент. Лист с более высоким градиентом/ошибкой используется для дальнейшего роста в LGBM. В итоге, мы не рассчитываем значение градиента на всей выборке(а, значит, скорость обучения будет пониже) и делаем subsample объектов. В целом, это довольно похоже на мини батч реализацию стохастического градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378002aa",
   "metadata": {},
   "source": [
    "Основное предположение, сделанное здесь, состоит в том, что образцы с обучающими экземплярами с небольшими градиентами имеют меньшую ошибку обучения и уже хорошо обучены. Чтобы сохранить такое же распределение данных, при вычислении прироста информации GOSS вводит постоянный множитель для экземпляров данных с небольшими градиентами. Таким образом, GOSS обеспечивает хороший баланс между уменьшением количества экземпляров данных и сохранением точности изученных деревьев решений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194b6c9",
   "metadata": {},
   "source": [
    "Настроим гиперпараметры следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817078e1",
   "metadata": {},
   "source": [
    "- 1-й шаг. Поработаем с общей сложностью модели, т.е. с гиперпараметрами, отвечающими за регуляризацию: max_depth, num_leaves(2^max_depth-1), lambda_l1, lambda_l2.Исходя из гипотезы раздела 4, глубина должна быть минимальной, следовательно, количество листьев тоже должно быть небольшим. Дополнительно можно поработать с bagging_fraction, который отвечает за долю выборки, участвующей в обучении, min_data_in_leaf и feature_fraction, отвечающим за минимальное количество признаков в листе при разбиении.\n",
    "- 2-й шаг. Поработаем со скоростью обучения(learning_rate) и количеством итераций(num_iterations). Сначала найдём наилучшее максимальное значение num_iterations, а learning_rate сделаем наилучшим минимально возможным (исходя из ключевой идеи LGBM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db48adb6",
   "metadata": {},
   "source": [
    "Также можно обозначить список категориальных переменных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb43be",
   "metadata": {},
   "source": [
    "Для калибровки вероятности будем использовать дополнительное сэмлирование или подбор по порогу - пересчение всех трёх кривых по метрикам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in new_cat:\n",
    "    train_df[feature] = train_df[feature].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26daef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['Credit Default']\n",
    "X = train_df.drop('Credit Default', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.3, random_state=21)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11798d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_lightgbm = lgbm.LGBMClassifier(random_state=43, \n",
    "                                     boosting_type='dart',\n",
    "                                     metric='logloss',\n",
    "                                     silent=False, \n",
    "                                     scoring='f1',\n",
    "                                     learning_rate=0.07, \n",
    "                                     max_depth=3, \n",
    "                                     min_data_in_leaf=15,\n",
    "                                     num_leaves=5, \n",
    "                                     num_iterations=100, \n",
    "                                     is_unbalance=True,\n",
    "                                     data_random_seed=17, \n",
    "                                     feature_fraction=0.95)\n",
    "\n",
    "model_lightgbm.fit(X_train, y_train, categorical_feature=new_cat)\n",
    "\n",
    "y_train_pred = model_lightgbm.predict(X_train)\n",
    "y_test_pred = model_lightgbm.predict(X_test)\n",
    "\n",
    "get_classification_report(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76834188",
   "metadata": {},
   "source": [
    "Посомтрим на кривые валидации и обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_learning_curve_plot(model_lightgbm, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3660160f",
   "metadata": {},
   "source": [
    "Оценим порог вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066cc97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = model_lightgbm.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffeace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_proba_calibration_plots(y_test_proba, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a664be",
   "metadata": {},
   "source": [
    "Отберём признаки по feature_importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_top = show_feature_importances(X_train.columns, model_lightgbm.feature_importances_, get_top=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_lightgbm = lgbm.LGBMClassifier(random_state=43, \n",
    "                                     boosting_type='dart',\n",
    "                                     metric='logloss',\n",
    "                                     silent=False, \n",
    "                                     scoring='f1',\n",
    "                                     learning_rate=0.07, \n",
    "                                     max_depth=3, \n",
    "                                     min_data_in_leaf=15,\n",
    "                                     num_leaves=5, \n",
    "                                     num_iterations=100, \n",
    "                                     is_unbalance=True,\n",
    "                                     data_random_seed=17, \n",
    "                                     feature_fraction=0.95)\n",
    "\n",
    "model_lightgbm.fit(X_train[important_features_top], y_train)\n",
    "\n",
    "y_train_pred = model_lightgbm.predict(X_train[important_features_top])\n",
    "y_test_pred = model_lightgbm.predict(X_test[important_features_top])\n",
    "\n",
    "get_classification_report(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8b4a7",
   "metadata": {},
   "source": [
    "Оценки практически не изменились, всё что не вошло в feature_importance можно убрать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f97b9a",
   "metadata": {},
   "source": [
    "GOSS сработал хуже всех.Балансировка дополнительным сэмплированием привела к переобучению. Возможно, стоит сэмплировать на кроссвалидации, возможно этот метод неактуален для этой задачи. Можно оценить классификатор в целом по roc_auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30210cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_lgbm.pickle', 'wb') as f:\n",
    "    pickle.dump(model_lightgbm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bf6635",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ca081",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.replace([-np.inf, np.inf], [0, 0])\n",
    "X_test = X_test.replace([-np.inf, np.inf], [0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aec3c7",
   "metadata": {},
   "source": [
    "Обучаем c отобранными признаками со случайным лесом в роли base estimator. Из base estimator стараемся делать \"пеньки\", а после настраивать скорость обучения и количество листьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d62e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ada = AdaBoostClassifier(RandomForestClassifier(max_depth=1, min_samples_leaf=5, criterion='gini',\n",
    "                                               min_samples_split=5, class_weight='balanced',\n",
    "                                               max_leaf_nodes=80,\n",
    "                                                random_state=43, n_jobs=-1),\n",
    "                         algorithm='SAMME.R', random_state=43,\n",
    "                        learning_rate=0.2, n_estimators=32)\n",
    "ada.fit(X_train[important_features_top], y_train)\n",
    "\n",
    "y_train_pred = ada.predict(X_train[important_features_top])\n",
    "y_test_pred = ada.predict(X_test[important_features_top])\n",
    "\n",
    "get_classification_report(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba3f5cc",
   "metadata": {},
   "source": [
    "Слегка отличаются precision и recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1786738",
   "metadata": {},
   "source": [
    "Калибровку здесь провести нельзя, поскольку алгоритм строит только разделяющую гиперплоскость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ada.pickle', 'wb') as f:\n",
    "    pickle.dump(ada, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68988fe",
   "metadata": {},
   "source": [
    "# Ensemble modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ab312",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lr.fit(X_train[important_features_top], y_train)\n",
    "lgbm = model_lightgbm.fit(X_train[important_features_top], y_train)\n",
    "ada = ada.fit(X_train[important_features_top], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713df73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = pd.Series(lr.predict(X_test[important_features_top]), name='lr')\n",
    "model1 = pd.Series(lgbm.predict(X_test[important_features_top]), name='lgbm')\n",
    "model2 = pd.Series(ada.predict(X_test[important_features_top]), name='ada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a374c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_results = pd.concat([model0, model1, model2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d7341",
   "metadata": {},
   "source": [
    "Оценим взаимосвязи результатов классификации при помощи корреляции Пирсона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b28a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_plot(ensemble_results, method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad451a",
   "metadata": {},
   "source": [
    "Довольно сильно коррелируют результаты LGBM и AdaBoost, но в целом, можно попытаться улучшить модель, поскольку есть не очень коррелирующих результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b3aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vote = VotingClassifier(estimators=[('lr', lr), ('lgbm', lgbm)],\n",
    "                       voting='soft', #для расчёта вероятности\n",
    "                       n_jobs=-1,\n",
    "                       weights=[0.5, 10])\n",
    "\n",
    "vote.fit(X_train[important_features_top], y_train)\n",
    "y_train_pred = vote.predict(X_train[important_features_top])\n",
    "y_test_pred = vote.predict(X_test[important_features_top])\n",
    "\n",
    "get_classification_report(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a3304",
   "metadata": {},
   "source": [
    "Результаты практически не изменились."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038005f0",
   "metadata": {},
   "source": [
    "Посмотрим на порог вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f2e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = vote.predict_proba(X_test[important_features_top])[:, 1]\n",
    "show_proba_calibration_plots(y_test_proba, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2298b15a",
   "metadata": {},
   "source": [
    "В итоге выберем LGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3dee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_processed.csv', encoding='utf-8')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9afeff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parabolize(test_df, 2, ['Credit Score', 'Annual Income', 'Current Loan Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a6ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lightgbm.fit(train_df[important_features_top], train_df['Credit Default'])\n",
    "y_pred = model_lightgbm.predict(test_df[important_features_top])\n",
    "is_default = pd.DataFrame(y_pred, columns=['Credit Default'])\n",
    "is_default.to_csv('final_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da046296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
